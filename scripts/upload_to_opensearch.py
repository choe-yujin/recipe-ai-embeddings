# ============================================================================
# AWS OpenSearch ë°ì´í„° ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸ (ì™„ì „ ìˆ˜ì • ë²„ì „)
# ============================================================================
# ëª©ì : 1136ê°œ ë ˆì‹œí”¼ì™€ ì•½ 500ê°œ ìž¬ë£Œì˜ ë²¡í„° ìž„ë² ë”©ì„ AWS OpenSearchì— ì—…ë¡œë“œ
# ì‚¬ìš©ë²•: python upload_to_opensearch.py
# í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜: OPENSEARCH_HOST, OPENSEARCH_USERNAME, OPENSEARCH_PASSWORD
# ============================================================================

import json
import os
from opensearchpy import OpenSearch, helpers
from dotenv import load_dotenv
import time

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ============================================================================
# OpenSearch í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
# ============================================================================

def create_opensearch_client():
    """AWS OpenSearch í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    host = os.getenv('OPENSEARCH_HOST')
    username = os.getenv('OPENSEARCH_USERNAME')
    password = os.getenv('OPENSEARCH_PASSWORD')
    
    if username and password:
        print("ðŸ”‘ Username/Password ì¸ì¦ ì‚¬ìš©")
        return OpenSearch(
            hosts=[{'host': host, 'port': 443}],
            http_auth=(username, password),
            use_ssl=True,
            verify_certs=True,
            ssl_show_warn=False,
            timeout=60,
            max_retries=10,
            retry_on_timeout=True
        )
    else:
        print("ðŸ”‘ IAM ì¸ì¦ ì‚¬ìš©")
        try:
            import boto3
            from requests_aws4auth import AWS4Auth
            
            region = os.getenv('AWS_REGION', 'ap-northeast-2')
            service = 'es'
            credentials = boto3.Session().get_credentials()
            awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, service, session_token=credentials.token)
            
            return OpenSearch(
                hosts=[{'host': host, 'port': 443}],
                http_auth=awsauth,
                use_ssl=True,
                verify_certs=True,
                ssl_show_warn=False,
                timeout=60,
                max_retries=10,
                retry_on_timeout=True
            )
        except ImportError:
            print("âŒ boto3 ë˜ëŠ” requests_aws4auth íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤")
            return None

# OpenSearch í´ë¼ì´ì–¸íŠ¸ ìƒì„±
client = create_opensearch_client()
if not client:
    print("âŒ OpenSearch í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨")
    exit(1)

# ============================================================================
# ì¸ë±ìŠ¤ ì„¤ì • ë° ë§¤í•‘ ì •ì˜ (AWS OpenSearch í˜¸í™˜)
# ============================================================================

RECIPE_INDEX = 'recipes'
INGREDIENT_INDEX = 'ingredients'

# ë ˆì‹œí”¼ ì¸ë±ìŠ¤ ë§¤í•‘ ì„¤ì •
recipe_mapping = {
    "settings": {
        "index": {
            "knn": True,
            "knn.algo_param.ef_search": 100,
            "knn.space_type": "cosinesimil"
        },
        "number_of_shards": 1,
        "number_of_replicas": 2,            # ë³µì œë³¸ 2ê°œë¡œ ì„¤ì • (3ê°œ AZìš© ìµœì í™”)
        "analysis": {
            "analyzer": {
                "korean_analyzer": {
                    "type": "custom",
                    "tokenizer": "nori_tokenizer",
                    "filter": ["lowercase", "nori_part_of_speech"]
                }
            },
            "tokenizer": {
                "nori_tokenizer": {
                    "type": "nori_tokenizer",
                    "decompound_mode": "mixed"
                }
            },
            "filter": {
                "nori_part_of_speech": {
                    "type": "nori_part_of_speech",
                    "stoptags": ["E", "IC", "J", "MAG", "MM", "SP", "SSC", "SSO", "SC", "SE", "XPN", "XSA", "XSN", "XSV", "UNA", "NA", "VSV"]
                }
            }
        }
    },
    "mappings": {
        "properties": {
            "recipe_id": {"type": "keyword"},
            "name": {"type": "text", "analyzer": "korean_analyzer"},
            "ingredients": {"type": "text", "analyzer": "korean_analyzer"},
            "category": {"type": "keyword"},
            "cooking_method": {"type": "keyword"},
            "hashtag": {"type": "text", "analyzer": "korean_analyzer"},
            "embedding": {
                "type": "knn_vector",
                "dimension": 1536,
                "method": {
                    "name": "hnsw",
                    "space_type": "cosinesimil",
                    "engine": "nmslib",
                    "parameters": {
                        "ef_construction": 128,
                        "m": 24
                    }
                }
            },
            "embedding_text": {"type": "text"},
            "created_at": {"type": "date"}
        }
    }
}

# ìž¬ë£Œ ì¸ë±ìŠ¤ ë§¤í•‘ ì„¤ì •
ingredient_mapping = {
    "settings": {
        "index": {
            "knn": True,
            "knn.algo_param.ef_search": 100,
            "knn.space_type": "cosinesimil"
        },
        "number_of_shards": 1,
        "number_of_replicas": 2,            # ë³µì œë³¸ 2ê°œë¡œ ì„¤ì • (3ê°œ AZìš© ìµœì í™”)
        "analysis": {
            "analyzer": {
                "korean_analyzer": {
                    "type": "custom",
                    "tokenizer": "nori_tokenizer",
                    "filter": ["lowercase", "nori_part_of_speech"]
                }
            },
            "tokenizer": {
                "nori_tokenizer": {
                    "type": "nori_tokenizer",
                    "decompound_mode": "mixed"
                }
            },
            "filter": {
                "nori_part_of_speech": {
                    "type": "nori_part_of_speech",
                    "stoptags": ["E", "IC", "J", "MAG", "MM", "SP", "SSC", "SSO", "SC", "SE", "XPN", "XSA", "XSN", "XSV", "UNA", "NA", "VSV"]
                }
            }
        }
    },
    "mappings": {
        "properties": {
            "ingredient_id": {"type": "long"},
            "name": {"type": "text", "analyzer": "korean_analyzer"},
            "aliases": {"type": "text", "analyzer": "korean_analyzer"},
            "category": {"type": "keyword"},
            "embedding": {
                "type": "knn_vector",
                "dimension": 1536,
                "method": {
                    "name": "hnsw",
                    "space_type": "cosinesimil",
                    "engine": "nmslib",
                    "parameters": {
                        "ef_construction": 128,
                        "m": 24
                    }
                }
            },
            "embedding_text": {"type": "text"},
            "created_at": {"type": "date"}
        }
    }
}

# ============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ============================================================================

def test_connection():
    """AWS OpenSearch ì„œë²„ì™€ì˜ ì—°ê²°ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
    try:
        info = client.info()
        print(f"âœ… AWS OpenSearch ì—°ê²° ì„±ê³µ!")
        print(f"   - ë²„ì „: {info['version']['number']}")
        print(f"   - í´ëŸ¬ìŠ¤í„°: {info['cluster_name']}")
        return True
    except Exception as e:
        print(f"âŒ AWS OpenSearch ì—°ê²° ì‹¤íŒ¨: {e}")
        return False

def delete_index_if_exists(index_name):
    """ì¸ë±ìŠ¤ê°€ ì¡´ìž¬í•˜ë©´ ì‚­ì œí•©ë‹ˆë‹¤."""
    try:
        if client.indices.exists(index=index_name):
            client.indices.delete(index=index_name)
            print(f"ðŸ—‘ï¸ ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ: {index_name}")
            time.sleep(2)
    except Exception as e:
        print(f"âš ï¸ ì¸ë±ìŠ¤ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {e}")

def create_index(index_name, mapping):
    """AWS OpenSearchì— ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        delete_index_if_exists(index_name)
        response = client.indices.create(index=index_name, body=mapping)
        print(f"âœ… ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ: {index_name}")
        time.sleep(3)
        return True
    except Exception as e:
        print(f"âŒ ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨ {index_name}: {e}")
        return False

def validate_embedding_data(data):
    """ìž„ë² ë”© ë°ì´í„°ì˜ ìœ íš¨ì„±ì„ ê²€ì‚¬í•©ë‹ˆë‹¤."""
    valid_data = []
    
    for item in data:
        embedding = item.get('embedding')
        
        if embedding and isinstance(embedding, list) and len(embedding) == 1536:
            if all(isinstance(x, (int, float)) for x in embedding):
                valid_data.append(item)
            else:
                print(f"âš ï¸ ìž„ë² ë”© ê°’ì´ ìˆ«ìžê°€ ì•„ë‹˜: {item.get('name', item.get('recipe_id', 'Unknown'))}")
        else:
            print(f"âš ï¸ ìž˜ëª»ëœ ìž„ë² ë”© ì°¨ì›: {item.get('name', item.get('recipe_id', 'Unknown'))}")
    
    print(f"ðŸ“Š ìœ íš¨í•œ ë°ì´í„°: {len(valid_data)}/{len(data)}")
    return valid_data

def preprocess_ingredient_data(ingredients):
    """ìž¬ë£Œ ë°ì´í„°ë¥¼ AWS OpenSearch ì—…ë¡œë“œìš©ìœ¼ë¡œ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    processed = []
    
    for ingredient in ingredients:
        aliases = ingredient.get('aliases', [])
        if isinstance(aliases, list):
            aliases_text = ' '.join(str(alias) for alias in aliases)
        else:
            aliases_text = str(aliases)
        
        processed_item = {
            "ingredient_id": ingredient.get('ingredient_id'),
            "name": ingredient.get('name'),
            "aliases": aliases_text,
            "category": ingredient.get('category'),
            "embedding": ingredient.get('embedding'),
            "embedding_text": ingredient.get('embedding_text'),
            "created_at": ingredient.get('created_at')
        }
        processed.append(processed_item)
    
    return processed

def preprocess_recipe_data(recipes):
    """ë ˆì‹œí”¼ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    return recipes

def bulk_upload(index_name, data, batch_size=20):
    """
    ëŒ€ëŸ‰ì˜ ë°ì´í„°ë¥¼ AWS OpenSearchì— ë°°ì¹˜ ì—…ë¡œë“œí•©ë‹ˆë‹¤.
    ì •í™•í•œ ì„±ê³µ/ì‹¤íŒ¨ ì¹´ìš´íŒ…ê³¼ ì˜¤ë¥˜ ë¡œê·¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    """
    actions = []
    total = len(data)
    success_count = 0
    error_count = 0
    
    print(f"ðŸ“¤ {index_name} ì—…ë¡œë“œ ì‹œìž‘: {total}ê°œ ë¬¸ì„œ")
    
    for i, item in enumerate(data, 1):
        # ë¬¸ì„œ ID ì„¤ì •
        doc_id = None
        if 'recipe_id' in item:
            doc_id = item['recipe_id']
        elif 'ingredient_id' in item:
            doc_id = item['ingredient_id']
        
        action = {
            "_index": index_name,
            "_source": item
        }
        
        if doc_id:
            action["_id"] = str(doc_id)
            
        actions.append(action)
        
        # ë°°ì¹˜ í¬ê¸°ì— ë„ë‹¬í•˜ê±°ë‚˜ ë§ˆì§€ë§‰ ë¬¸ì„œì¸ ê²½ìš°
        if len(actions) >= batch_size or i == total:
            try:
                # ëŒ€ëŸ‰ ì—…ë¡œë“œ ì‹¤í–‰
                success, errors = helpers.bulk(
                    client, 
                    actions, 
                    timeout=600,
                    max_retries=3,
                    initial_backoff=2,
                    max_backoff=300
                )
                
                # ì„±ê³µ/ì‹¤íŒ¨ ì¹´ìš´íŒ…
                success_count += success
                
                # ì˜¤ë¥˜ ì²˜ë¦¬
                if errors:
                    error_count += len(errors)
                    print(f"   âš ï¸ ë°°ì¹˜ ì˜¤ë¥˜ {len(errors)}ê°œ:")
                    for error in errors[:3]:  # ì²˜ìŒ 3ê°œ ì˜¤ë¥˜ë§Œ í‘œì‹œ
                        error_info = error.get('index', {}).get('error', {})
                        error_type = error_info.get('type', 'unknown')
                        error_reason = error_info.get('reason', 'unknown reason')
                        print(f"      - {error_type}: {error_reason}")
                    if len(errors) > 3:
                        print(f"      - ... ë° {len(errors)-3}ê°œ ì¶”ê°€ ì˜¤ë¥˜")
                
                # ì§„í–‰ë¥  ì¶œë ¥
                print(f"   ì§„í–‰ìƒí™©: {i}/{total} ({(i/total)*100:.1f}%) - ì„±ê³µ: {success_count}, ì‹¤íŒ¨: {error_count}")
                
                actions = []
                time.sleep(1)  # API ë¶€í•˜ ë°©ì§€
                
            except Exception as e:
                print(f"âŒ ë°°ì¹˜ ì—…ë¡œë“œ ì‹¬ê°í•œ ì˜¤ë¥˜: {e}")
                error_count += len(actions)
                
                # ê°œë³„ ì—…ë¡œë“œ ì‹œë„
                individual_success = 0
                for j, action in enumerate(actions):
                    try:
                        response = client.index(
                            index=action["_index"], 
                            body=action["_source"], 
                            id=action.get("_id"),
                            timeout=60
                        )
                        if response.get('result') in ['created', 'updated']:
                            individual_success += 1
                    except Exception as individual_error:
                        print(f"   ê°œë³„ ì—…ë¡œë“œ ì‹¤íŒ¨ [{j+1}]: {str(individual_error)[:100]}...")
                
                success_count += individual_success
                error_count = error_count - len(actions) + (len(actions) - individual_success)
                actions = []
    
    print(f"âœ… {index_name} ì—…ë¡œë“œ ì™„ë£Œ: ì„±ê³µ {success_count}/{total}, ì‹¤íŒ¨ {error_count}")
    return success_count == total

def verify_upload():
    """ì—…ë¡œë“œëœ ë°ì´í„°ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤."""
    print("\nðŸ“‹ ì—…ë¡œë“œ ê²°ê³¼ ê²€ì¦:")
    
    time.sleep(5)  # ì¸ë±ì‹± ì™„ë£Œ ëŒ€ê¸°
    
    # ë ˆì‹œí”¼ ì¸ë±ìŠ¤ í™•ì¸
    try:
        recipe_count = client.count(index=RECIPE_INDEX)["count"]
        print(f"   ðŸ“Š ë ˆì‹œí”¼: {recipe_count}ê°œ")
        
        sample = client.search(index=RECIPE_INDEX, body={"query": {"match_all": {}}, "size": 1})
        if sample["hits"]["hits"]:
            sample_recipe = sample["hits"]["hits"][0]["_source"]
            print(f"   ðŸ“ ìƒ˜í”Œ ë ˆì‹œí”¼: {sample_recipe.get('name', 'N/A')}")
            print(f"   ðŸ”¢ ìž„ë² ë”© ì°¨ì›: {len(sample_recipe.get('embedding', []))}")
            
    except Exception as e:
        print(f"   âŒ ë ˆì‹œí”¼ í™•ì¸ ì‹¤íŒ¨: {e}")
    
    # ìž¬ë£Œ ì¸ë±ìŠ¤ í™•ì¸
    try:
        ingredient_count = client.count(index=INGREDIENT_INDEX)["count"]
        print(f"   ðŸ“Š ìž¬ë£Œ: {ingredient_count}ê°œ")
        
        sample = client.search(index=INGREDIENT_INDEX, body={"query": {"match_all": {}}, "size": 1})
        if sample["hits"]["hits"]:
            sample_ingredient = sample["hits"]["hits"][0]["_source"]
            print(f"   ðŸ“ ìƒ˜í”Œ ìž¬ë£Œ: {sample_ingredient.get('name', 'N/A')}")
            print(f"   ðŸ·ï¸ ì¹´í…Œê³ ë¦¬: {sample_ingredient.get('category', 'N/A')}")
            
    except Exception as e:
        print(f"   âŒ ìž¬ë£Œ í™•ì¸ ì‹¤íŒ¨: {e}")

def test_simple_upload():
    """ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ë¬¸ì„œë¡œ ì—…ë¡œë“œ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
    print("\nðŸ§ª ê°„ë‹¨í•œ ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸:")
    
    try:
        test_doc = {
            "recipe_id": "test_001",
            "name": "í…ŒìŠ¤íŠ¸ ë ˆì‹œí”¼",
            "ingredients": "í…ŒìŠ¤íŠ¸ ìž¬ë£Œ",
            "category": "í…ŒìŠ¤íŠ¸",
            "cooking_method": "í…ŒìŠ¤íŠ¸",
            "hashtag": "í…ŒìŠ¤íŠ¸",
            "embedding": [0.1] * 1536,
            "embedding_text": "í…ŒìŠ¤íŠ¸ìš© ìž„ë² ë”© í…ìŠ¤íŠ¸",
            "created_at": "2025-05-30T00:00:00Z"
        }
        
        response = client.index(
            index="recipes",
            body=test_doc,
            id="test_001",
            timeout=60
        )
        
        print(f"   âœ… í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ì—…ë¡œë“œ ì„±ê³µ: {response['result']}")
        
        # í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ì‚­ì œ
        client.delete(index="recipes", id="test_001")
        return True
        
    except Exception as e:
        print(f"   âŒ í…ŒìŠ¤íŠ¸ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

def test_vector_search():
    """ë²¡í„° ê²€ìƒ‰ ê¸°ëŠ¥ì„ ìžì—°ì–´ë¡œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
    print("\nðŸ§ª ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸:")
    
    # ì‹¤ì œ OpenAI APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, 
    # ê¸°ì¡´ ë°ì´í„°ì—ì„œ ìž„ë² ë”©ì„ ê°€ì ¸ì™€ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    try:
        # 1. ê¸°ì¡´ ë°ì´í„°ì—ì„œ ìƒ˜í”Œ ìž„ë² ë”© ê°€ì ¸ì˜¤ê¸°
        print("\n   ðŸ” ìž¬ë£Œ ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸:")
        
        # ìƒ˜í”Œ ìž¬ë£Œ ê²€ìƒ‰ (ë°€ê°€ë£¨ì™€ ìœ ì‚¬í•œ ìž¬ë£Œ ì°¾ê¸°)
        sample_ingredient = client.search(
            index=INGREDIENT_INDEX,
            body={"query": {"match": {"name": "ë°€ê°€ë£¨"}}, "size": 1}
        )
        
        if sample_ingredient["hits"]["hits"]:
            flour_embedding = sample_ingredient["hits"]["hits"][0]["_source"]["embedding"]
            print(f"   ðŸ“ ê²€ìƒ‰ ê¸°ì¤€: 'ë°€ê°€ë£¨' (ê³¡ë¥˜/ë¶„ë§)")
            
            # ë°€ê°€ë£¨ì™€ ìœ ì‚¬í•œ ìž¬ë£Œ ê²€ìƒ‰
            similar_ingredients = client.search(
                index=INGREDIENT_INDEX,
                body={
                    "size": 5,
                    "query": {
                        "knn": {
                            "embedding": {
                                "vector": flour_embedding,
                                "k": 5
                            }
                        }
                    }
                }
            )
            
            print(f"   âœ… ìœ ì‚¬í•œ ìž¬ë£Œ {len(similar_ingredients['hits']['hits'])}ê°œ ë°œê²¬:")
            for i, hit in enumerate(similar_ingredients['hits']['hits'][:3], 1):
                source = hit["_source"]
                score = hit["_score"]
                print(f"      {i}. {source['name']} ({source['category']}) - ìœ ì‚¬ë„: {score:.3f}")
        
        print("\n   ðŸ” ë ˆì‹œí”¼ ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸:")
        
        # ìƒ˜í”Œ ë ˆì‹œí”¼ ê²€ìƒ‰ (ë³¶ìŒ ìš”ë¦¬ì™€ ìœ ì‚¬í•œ ë ˆì‹œí”¼ ì°¾ê¸°)
        sample_recipe = client.search(
            index=RECIPE_INDEX,
            body={"query": {"match": {"name": "ë³¶ìŒ"}}, "size": 1}
        )
        
        if sample_recipe["hits"]["hits"]:
            stir_fry_embedding = sample_recipe["hits"]["hits"][0]["_source"]["embedding"]
            recipe_name = sample_recipe["hits"]["hits"][0]["_source"]["name"]
            print(f"   ðŸ“ ê²€ìƒ‰ ê¸°ì¤€: '{recipe_name}' (ë³¶ìŒ ìš”ë¦¬)")
            
            # ë³¶ìŒê³¼ ìœ ì‚¬í•œ ë ˆì‹œí”¼ ê²€ìƒ‰
            similar_recipes = client.search(
                index=RECIPE_INDEX,
                body={
                    "size": 5,
                    "query": {
                        "knn": {
                            "embedding": {
                                "vector": stir_fry_embedding,
                                "k": 5
                            }
                        }
                    }
                }
            )
            
            print(f"   âœ… ìœ ì‚¬í•œ ë ˆì‹œí”¼ {len(similar_recipes['hits']['hits'])}ê°œ ë°œê²¬:")
            for i, hit in enumerate(similar_recipes['hits']['hits'][:3], 1):
                source = hit["_source"]
                score = hit["_score"]
                ingredients_preview = source.get('ingredients', '')[:30] + "..." if len(source.get('ingredients', '')) > 30 else source.get('ingredients', '')
                print(f"      {i}. {source['name']} - ìœ ì‚¬ë„: {score:.3f}")
                print(f"         ìž¬ë£Œ: {ingredients_preview}")
                print(f"         ì¹´í…Œê³ ë¦¬: {source.get('category', 'N/A')}")
        
        # 3. íŠ¹ì • ìž¬ë£Œ ê¸°ë°˜ ë ˆì‹œí”¼ ì¶”ì²œ í…ŒìŠ¤íŠ¸
        print("\n   ðŸ” íŠ¹ì • ìž¬ë£Œ ê¸°ë°˜ ë ˆì‹œí”¼ ì¶”ì²œ í…ŒìŠ¤íŠ¸:")
        
        # ë‹­ê³ ê¸° ìž„ë² ë”© ê°€ì ¸ì˜¤ê¸°
        chicken_search = client.search(
            index=INGREDIENT_INDEX,
            body={"query": {"match": {"name": "ë‹­ê³ ê¸°"}}, "size": 1}
        )
        
        if chicken_search["hits"]["hits"]:
            chicken_embedding = chicken_search["hits"]["hits"][0]["_source"]["embedding"]
            print(f"   ðŸ“ ê²€ìƒ‰ ìž¬ë£Œ: 'ë‹­ê³ ê¸°'")
            
            # ë‹­ê³ ê¸°ë¥¼ ì‚¬ìš©í•˜ëŠ” ë ˆì‹œí”¼ ê²€ìƒ‰
            chicken_recipes = client.search(
                index=RECIPE_INDEX,
                body={
                    "size": 3,
                    "query": {
                        "knn": {
                            "embedding": {
                                "vector": chicken_embedding,
                                "k": 10
                            }
                        }
                    }
                }
            )
            
            print(f"   âœ… ë‹­ê³ ê¸° í™œìš© ë ˆì‹œí”¼ ì¶”ì²œ:")
            for i, hit in enumerate(chicken_recipes['hits']['hits'], 1):
                source = hit["_source"]
                score = hit["_score"]
                print(f"      {i}. {source['name']} - ê´€ë ¨ë„: {score:.3f}")
                if 'ë‹­' in source.get('ingredients', ''):
                    print(f"         âœ“ ë‹­ê³ ê¸° í¬í•¨ í™•ì¸")
        
        # 4. ì¹´í…Œê³ ë¦¬ë³„ ìž¬ë£Œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        print("\n   ðŸ” ì¹´í…Œê³ ë¦¬ë³„ ìž¬ë£Œ ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸:")
        
        # ì¡°ë¯¸ë£Œ ì¹´í…Œê³ ë¦¬ ìž¬ë£Œ ê²€ìƒ‰
        seasoning_search = client.search(
            index=INGREDIENT_INDEX,
            body={"query": {"match": {"name": "ì†Œê¸ˆ"}}, "size": 1}
        )
        
        if seasoning_search["hits"]["hits"]:
            salt_embedding = seasoning_search["hits"]["hits"][0]["_source"]["embedding"]
            print(f"   ðŸ“ ê²€ìƒ‰ ê¸°ì¤€: 'ì†Œê¸ˆ' (ì¡°ë¯¸ë£Œ)")
            
            # ì†Œê¸ˆê³¼ ìœ ì‚¬í•œ ì¡°ë¯¸ë£Œ ê²€ìƒ‰
            similar_seasonings = client.search(
                index=INGREDIENT_INDEX,
                body={
                    "size": 5,
                    "query": {
                        "knn": {
                            "embedding": {
                                "vector": salt_embedding,
                                "k": 5
                            }
                        }
                    }
                }
            )
            
            print(f"   âœ… ìœ ì‚¬í•œ ì¡°ë¯¸ë£Œ:")
            for i, hit in enumerate(similar_seasonings['hits']['hits'][:3], 1):
                source = hit["_source"]
                score = hit["_score"]
                print(f"      {i}. {source['name']} ({source['category']}) - ìœ ì‚¬ë„: {score:.3f}")
        
    except Exception as e:
        print(f"   âŒ ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        print(f"   ì˜¤ë¥˜ ì„¸ë¶€ì‚¬í•­: {str(e)}")

def test_natural_language_search():
    """ìžì—°ì–´ ê²€ìƒ‰ ì‹œë®¬ë ˆì´ì…˜ (í…ìŠ¤íŠ¸ + ë²¡í„° ì¡°í•©)"""
    print("\nðŸ—£ï¸ ìžì—°ì–´ ê²€ìƒ‰ ì‹œë®¬ë ˆì´ì…˜:")
    
    search_scenarios = [
        {
            "query": "ê°„ë‹¨í•œ ì•„ì¹¨ ìš”ë¦¬",
            "description": "ì•„ì¹¨ì— ë§Œë“¤ê¸° ì‰¬ìš´ ìš”ë¦¬ ì°¾ê¸°",
            "keywords": ["ê°„ë‹¨", "ì•„ì¹¨", "ì‰¬ìš´"]
        },
        {
            "query": "ë§¤ìš´ ë‹­ê³ ê¸° ìš”ë¦¬",
            "description": "ë§¤ìš´ë§› ë‹­ê³ ê¸° ë ˆì‹œí”¼ ì°¾ê¸°", 
            "keywords": ["ë§¤ìš´", "ë‹­", "ê³ ì¶”"]
        },
        {
            "query": "ê±´ê°•í•œ ì±„ì†Œ ìš”ë¦¬",
            "description": "ì˜ì–‘ê°€ ìžˆëŠ” ì±„ì†Œ ì¤‘ì‹¬ ìš”ë¦¬",
            "keywords": ["ê±´ê°•", "ì±„ì†Œ", "ì˜ì–‘"]
        }
    ]
    
    for scenario in search_scenarios:
        print(f"\n   ðŸ” ì‹œë‚˜ë¦¬ì˜¤: '{scenario['query']}'")
        print(f"   ðŸ“ ì„¤ëª…: {scenario['description']}")
        
        try:
            # í‚¤ì›Œë“œ ê¸°ë°˜ í…ìŠ¤íŠ¸ ê²€ìƒ‰
            text_results = client.search(
                index=RECIPE_INDEX,
                body={
                    "size": 3,
                    "query": {
                        "multi_match": {
                            "query": " ".join(scenario['keywords']),
                            "fields": ["name^2", "ingredients", "hashtag"],
                            "type": "best_fields"
                        }
                    }
                }
            )
            
            print(f"   âœ… í…ìŠ¤íŠ¸ ê²€ìƒ‰ ê²°ê³¼ ({len(text_results['hits']['hits'])}ê°œ):")
            for i, hit in enumerate(text_results['hits']['hits'], 1):
                source = hit["_source"]
                score = hit["_score"]
                print(f"      {i}. {source['name']} - ì ìˆ˜: {score:.3f}")
                print(f"         í•´ì‹œíƒœê·¸: {source.get('hashtag', 'N/A')}")
            
        except Exception as e:
            print(f"   âŒ ì‹œë‚˜ë¦¬ì˜¤ '{scenario['query']}' ê²€ìƒ‰ ì‹¤íŒ¨: {e}")

def test_ingredient_combination_search():
    """ìž¬ë£Œ ì¡°í•© ê¸°ë°˜ ë ˆì‹œí”¼ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    print("\nðŸ¥˜ ìž¬ë£Œ ì¡°í•© ë ˆì‹œí”¼ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸:")
    
    ingredient_combinations = [
        ["ê³„ëž€", "ë°€ê°€ë£¨"],
        ["ë‹­ê³ ê¸°", "ì–‘íŒŒ", "ê°„ìž¥"],
        ["ë¼ì§€ê³ ê¸°", "ë°°ì¶”", "ê³ ì¶§ê°€ë£¨"]
    ]
    
    for ingredients in ingredient_combinations:
        print(f"\n   ðŸ” ìž¬ë£Œ ì¡°í•©: {' + '.join(ingredients)}")
        
        try:
            # ë‹¤ì¤‘ ìž¬ë£Œ ê²€ìƒ‰
            should_queries = []
            for ingredient in ingredients:
                should_queries.append({"match": {"ingredients": ingredient}})
            
            combo_results = client.search(
                index=RECIPE_INDEX,
                body={
                    "size": 3,
                    "query": {
                        "bool": {
                            "should": should_queries,
                            "minimum_should_match": len(ingredients) - 1  # ìµœì†Œ n-1ê°œ ìž¬ë£Œ í¬í•¨
                        }
                    }
                }
            )
            
            print(f"   âœ… ì¶”ì²œ ë ˆì‹œí”¼ ({len(combo_results['hits']['hits'])}ê°œ):")
            for i, hit in enumerate(combo_results['hits']['hits'], 1):
                source = hit["_source"]
                score = hit["_score"]
                
                # í¬í•¨ëœ ìž¬ë£Œ í™•ì¸
                included_ingredients = []
                for ing in ingredients:
                    if ing in source.get('ingredients', ''):
                        included_ingredients.append(ing)
                
                print(f"      {i}. {source['name']} - ì ìˆ˜: {score:.3f}")
                print(f"         í¬í•¨ ìž¬ë£Œ: {', '.join(included_ingredients) if included_ingredients else 'ì—†ìŒ'}")
                print(f"         ì¡°ë¦¬ë²•: {source.get('cooking_method', 'N/A')}")
            
        except Exception as e:
            print(f"   âŒ ìž¬ë£Œ ì¡°í•© ê²€ìƒ‰ ì‹¤íŒ¨: {e}")

def detailed_status_check():
    """ìƒì„¸í•œ OpenSearch ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""
    print("\nðŸ” ìƒì„¸ ìƒíƒœ í™•ì¸:")
    
    try:
        # í´ëŸ¬ìŠ¤í„° ìƒíƒœ
        cluster_health = client.cluster.health()
        print(f"   ðŸ¥ í´ëŸ¬ìŠ¤í„° ìƒíƒœ: {cluster_health['status']}")
        print(f"   ðŸ“Š í™œì„± ìƒ¤ë“œ: {cluster_health['active_shards']}")
        print(f"   ðŸ”„ ìž¬ë°°ì¹˜ ì¤‘ì¸ ìƒ¤ë“œ: {cluster_health['relocating_shards']}")
        
        # ì¸ë±ìŠ¤ ìƒíƒœ
        indices_stats = client.indices.stats(index=[RECIPE_INDEX, INGREDIENT_INDEX])
        
        if RECIPE_INDEX in indices_stats['indices']:
            recipe_stats = indices_stats['indices'][RECIPE_INDEX]
            print(f"   ðŸ“ˆ ë ˆì‹œí”¼ ì¸ë±ìŠ¤ í¬ê¸°: {recipe_stats['total']['store']['size_in_bytes']} bytes")
            print(f"   ðŸ“ ë ˆì‹œí”¼ ë¬¸ì„œ ìˆ˜: {recipe_stats['total']['docs']['count']}")
        
        if INGREDIENT_INDEX in indices_stats['indices']:
            ingredient_stats = indices_stats['indices'][INGREDIENT_INDEX]
            print(f"   ðŸ“ˆ ìž¬ë£Œ ì¸ë±ìŠ¤ í¬ê¸°: {ingredient_stats['total']['store']['size_in_bytes']} bytes")
            print(f"   ðŸ“ ìž¬ë£Œ ë¬¸ì„œ ìˆ˜: {ingredient_stats['total']['docs']['count']}")
            
        # ìƒ˜í”Œ ê²€ìƒ‰
        print("\n   ðŸ” ìƒ˜í”Œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸:")
        
        # í…ìŠ¤íŠ¸ ê²€ìƒ‰
        text_search = client.search(
            index=RECIPE_INDEX,
            body={"query": {"match": {"name": "ë³¶ìŒ"}}, "size": 1}
        )
        print(f"   ðŸ“ 'ë³¶ìŒ' í…ìŠ¤íŠ¸ ê²€ìƒ‰: {text_search['hits']['total']['value']}ê°œ ê²°ê³¼")
        
        # ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰
        category_search = client.search(
            index=INGREDIENT_INDEX,
            body={"query": {"term": {"category": "ê³¡ë¥˜/ë¶„ë§"}}, "size": 1}
        )
        print(f"   ðŸ·ï¸ 'ê³¡ë¥˜/ë¶„ë§' ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰: {category_search['hits']['total']['value']}ê°œ ê²°ê³¼")
        
    except Exception as e:
        print(f"   âŒ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")

# ============================================================================
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ðŸš€ AWS OpenSearch ë²¡í„° ë°ì´í„° ì—…ë¡œë“œ ì‹œìž‘\n")
    
    # 1. í™˜ê²½ë³€ìˆ˜ í™•ì¸
    required_vars = ['OPENSEARCH_HOST']
    for var in required_vars:
        if not os.getenv(var):
            print(f"âŒ {var} í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return
    
    if not (os.getenv('OPENSEARCH_USERNAME') and os.getenv('OPENSEARCH_PASSWORD')):
        if not os.getenv('AWS_REGION'):
            print("âŒ ì¸ì¦ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            return
    
    # 2. OpenSearch ì—°ê²° í…ŒìŠ¤íŠ¸
    if not test_connection():
        return
    
    # 3. ì¸ë±ìŠ¤ ìƒì„±
    print("\nðŸ“‚ ì¸ë±ìŠ¤ ìƒì„±:")
    if not create_index(RECIPE_INDEX, recipe_mapping):
        return
    if not create_index(INGREDIENT_INDEX, ingredient_mapping):
        return
    
    # 3.5. ê°„ë‹¨í•œ ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸
    if not test_simple_upload():
        print("âŒ ê¸°ë³¸ ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    # 4. ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì •
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(current_dir)
    
    print("\nðŸ“¤ ë°ì´í„° ì—…ë¡œë“œ:")
    
    # 5-1. ë ˆì‹œí”¼ ë°ì´í„° ì—…ë¡œë“œ
    recipe_files = [
        os.path.join(project_root, "data", "recipe_embeddings.json"),
        os.path.join(current_dir, "recipe_embeddings.json"),
        "../data/recipe_embeddings.json"
    ]
    
    recipe_uploaded = False
    for recipe_file in recipe_files:
        if os.path.exists(recipe_file):
            print(f"ðŸ“ ë ˆì‹œí”¼ íŒŒì¼ ë¡œë“œ: {recipe_file}")
            try:
                with open(recipe_file, 'r', encoding='utf-8') as f:
                    recipes = json.load(f)
                
                valid_recipes = validate_embedding_data(recipes)
                if valid_recipes:
                    processed_recipes = preprocess_recipe_data(valid_recipes)
                    bulk_upload(RECIPE_INDEX, processed_recipes)
                    recipe_uploaded = True
                    break
                else:
                    print("âŒ ìœ íš¨í•œ ë ˆì‹œí”¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                    
            except Exception as e:
                print(f"âŒ ë ˆì‹œí”¼ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    if not recipe_uploaded:
        print("âŒ ë ˆì‹œí”¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    # 5-2. ìž¬ë£Œ ë°ì´í„° ì—…ë¡œë“œ
    ingredient_files = [
        os.path.join(project_root, "data", "ingredient_embeddings.json"),
        os.path.join(current_dir, "ingredient_embeddings.json"),
        "../data/ingredient_embeddings.json"
    ]
    
    ingredient_uploaded = False
    for ingredient_file in ingredient_files:
        if os.path.exists(ingredient_file):
            print(f"ðŸ“ ìž¬ë£Œ íŒŒì¼ ë¡œë“œ: {ingredient_file}")
            try:
                with open(ingredient_file, 'r', encoding='utf-8') as f:
                    ingredients = json.load(f)
                
                valid_ingredients = validate_embedding_data(ingredients)
                if valid_ingredients:
                    processed_ingredients = preprocess_ingredient_data(valid_ingredients)
                    bulk_upload(INGREDIENT_INDEX, processed_ingredients)
                    ingredient_uploaded = True
                    break
                else:
                    print("âŒ ìœ íš¨í•œ ìž¬ë£Œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                    
            except Exception as e:
                print(f"âŒ ìž¬ë£Œ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    if not ingredient_uploaded:
        print("âŒ ìž¬ë£Œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    # 6. ì—…ë¡œë“œ ê²°ê³¼ ê²€ì¦
    verify_upload()
    
    # 7. ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    test_vector_search()
    
    # 8. ìžì—°ì–´ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    test_natural_language_search()
    
    # 9. ìž¬ë£Œ ì¡°í•© ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    test_ingredient_combination_search()
    
    # 8. ìƒì„¸ ìƒíƒœ í™•ì¸
    detailed_status_check()
    
    print("\nðŸŽ‰ AWS OpenSearch ì—…ë¡œë“œ ì™„ë£Œ!")
    print("\nðŸ“– ë‹¤ìŒ ë‹¨ê³„:")
    print("   1. AI ì„œë²„ì—ì„œ kNN ê²€ìƒ‰ API êµ¬í˜„")
    print("   2. ë„¤íŠ¸ì›Œí¬ ì„¤ì •ì„ VPCë¡œ ë³µì› (ë³´ì•ˆ ê°•í™”)")
    print("   3. ë ˆì‹œí”¼ ì¶”ì²œ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸")

def check_only():
    """ì—…ë¡œë“œ ì—†ì´ í˜„ìž¬ ìƒíƒœë§Œ í™•ì¸í•˜ëŠ” í•¨ìˆ˜"""
    print("ðŸ” OpenSearch ìƒíƒœ í™•ì¸ë§Œ ì‹¤í–‰\n")
    
    if not test_connection():
        return
    
    verify_upload()
    test_vector_search()
    test_natural_language_search()
    test_ingredient_combination_search()
    detailed_status_check()

if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == "check":
        check_only()
    else:
        main()