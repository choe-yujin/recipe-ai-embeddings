# ============================================================================
# OpenSearch ë°ì´í„° ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸
# ============================================================================
# ëª©ì : 1136ê°œ ë ˆì‹œí”¼ì™€ ì•½ 500ê°œ ì¬ë£Œì˜ ë²¡í„° ì„ë² ë”©ì„ AWS OpenSearchì— ì—…ë¡œë“œ
# ì‚¬ìš©ë²•: python upload_to_opensearch.py
# í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜: OPENSEARCH_HOST, OPENSEARCH_USERNAME, OPENSEARCH_PASSWORD
# ============================================================================

import json
import os
from opensearchpy import OpenSearch, helpers
from dotenv import load_dotenv
import time

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
# OPENSEARCH_HOST, OPENSEARCH_USERNAME, OPENSEARCH_PASSWORD ë“±ì„ ì„¤ì •
load_dotenv()

# ============================================================================
# OpenSearch í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
# ============================================================================

def create_opensearch_client():
    """
    OpenSearch í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    ë‘ ê°€ì§€ ì¸ì¦ ë°©ì‹ì„ ì§€ì›:
    1. Username/Password ì¸ì¦ (Fine-grained access control)
    2. AWS IAM ì¸ì¦ (VPC ë‚´ë¶€ì—ì„œ ì‚¬ìš©)
    
    Returns:
        OpenSearch: ì„¤ì •ëœ OpenSearch í´ë¼ì´ì–¸íŠ¸ ê°ì²´
    """
    host = os.getenv('OPENSEARCH_HOST')
    username = os.getenv('OPENSEARCH_USERNAME')
    password = os.getenv('OPENSEARCH_PASSWORD')
    
    if username and password:
        # Username/Password ì¸ì¦ ë°©ì‹ (ì¶”ì²œ)
        print("ğŸ”‘ Username/Password ì¸ì¦ ì‚¬ìš©")
        return OpenSearch(
            hosts=[{'host': host, 'port': 443}],
            http_auth=(username, password),
            use_ssl=True,                    # HTTPS ì‚¬ìš©
            verify_certs=True,               # SSL ì¸ì¦ì„œ ê²€ì¦
            ssl_show_warn=False,             # SSL ê²½ê³  ìˆ¨ê¹€
            timeout=30,                      # ì—°ê²° íƒ€ì„ì•„ì›ƒ 30ì´ˆ
            max_retries=10,                  # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
            retry_on_timeout=True            # íƒ€ì„ì•„ì›ƒ ì‹œ ì¬ì‹œë„
        )
    else:
        # AWS IAM ì¸ì¦ ë°©ì‹ (VPC ë‚´ë¶€ì—ì„œ ì‚¬ìš©)
        print("ğŸ”‘ IAM ì¸ì¦ ì‚¬ìš©")
        try:
            import boto3
            from requests_aws4auth import AWS4Auth
            
            region = os.getenv('AWS_REGION', 'ap-northeast-2')
            service = 'es'
            credentials = boto3.Session().get_credentials()
            awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, service, session_token=credentials.token)
            
            return OpenSearch(
                hosts=[{'host': host, 'port': 443}],
                http_auth=awsauth,
                use_ssl=True,
                verify_certs=True,
                ssl_show_warn=False,
                timeout=30,
                max_retries=10,
                retry_on_timeout=True
            )
        except ImportError:
            print("âŒ boto3 ë˜ëŠ” requests_aws4auth íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤")
            print("pip install boto3 requests_aws4auth")
            return None

# OpenSearch í´ë¼ì´ì–¸íŠ¸ ìƒì„±
client = create_opensearch_client()
if not client:
    print("âŒ OpenSearch í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨")
    exit(1)

# ============================================================================
# ì¸ë±ìŠ¤ ì„¤ì • ë° ë§¤í•‘ ì •ì˜
# ============================================================================

# ì¸ë±ìŠ¤ ì´ë¦„ ìƒìˆ˜ ì •ì˜
RECIPE_INDEX = 'recipes'        # ë ˆì‹œí”¼ ì¸ë±ìŠ¤ëª…
INGREDIENT_INDEX = 'ingredients' # ì¬ë£Œ ì¸ë±ìŠ¤ëª…

# ë ˆì‹œí”¼ ì¸ë±ìŠ¤ ë§¤í•‘ ì„¤ì •
recipe_mapping = {
    "mappings": {
        "properties": {
            # ë ˆì‹œí”¼ ê¸°ë³¸ ì •ë³´
            "recipe_id": {"type": "keyword"},                    # ë ˆì‹œí”¼ ê³ ìœ  ID (ì •í™• ë§¤ì¹­ìš©)
            "name": {"type": "text", "analyzer": "nori"},        # ë ˆì‹œí”¼ëª… (í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„)
            "ingredients": {"type": "text", "analyzer": "nori"}, # ì¬ë£Œ ëª©ë¡ (ê²€ìƒ‰ ê°€ëŠ¥)
            "category": {"type": "keyword"},                     # ì¹´í…Œê³ ë¦¬ (í•„í„°ë§ìš©)
            "cooking_method": {"type": "keyword"},               # ì¡°ë¦¬ ë°©ë²• (í•„í„°ë§ìš©)
            "hashtag": {"type": "text", "analyzer": "nori"},     # í•´ì‹œíƒœê·¸ (ê²€ìƒ‰ ê°€ëŠ¥)
            
            # ë²¡í„° ì„ë² ë”© (AI ì¶”ì²œì˜ í•µì‹¬)
            "embedding": {
                "type": "dense_vector",    # ë²¡í„° íƒ€ì…
                "dims": 1536,              # OpenAI text-embedding-3-small ì°¨ì›ìˆ˜
                "index": True,             # ë²¡í„° ì¸ë±ì‹± í™œì„±í™”
                "similarity": "cosine"     # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì‚¬ìš©
            },
            
            # ë©”íƒ€ë°ì´í„°
            "embedding_text": {"type": "text"},  # ì„ë² ë”© ìƒì„±ì— ì‚¬ìš©ëœ ì›ë³¸ í…ìŠ¤íŠ¸
            "created_at": {"type": "date"}       # ìƒì„± ë‚ ì§œ
        }
    },
    "settings": {
        "number_of_shards": 1,      # ë‹¨ì¼ ìƒ¤ë“œ (ì†Œê·œëª¨ ë°ì´í„°ìš©)
        "number_of_replicas": 0,    # ë³µì œë³¸ ì—†ìŒ (ë‹¨ì¼ ë…¸ë“œìš©)
        "analysis": {
            "analyzer": {
                "nori": {               # í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ê¸°
                    "type": "nori",
                    # ë¶ˆìš©ì–´ íƒœê·¸ ì„¤ì • (ì¡°ì‚¬, ì–´ë¯¸ ë“± ì œì™¸)
                    "stoptags": ["E", "IC", "J", "MAG", "MM", "SP", "SSC", "SSO", "SC", "SE", "XPN", "XSA", "XSN", "XSV", "UNA", "NA", "VSV"]
                }
            }
        }
    }
}

# ì¬ë£Œ ì¸ë±ìŠ¤ ë§¤í•‘ ì„¤ì •
ingredient_mapping = {
    "mappings": {
        "properties": {
            # ì¬ë£Œ ê¸°ë³¸ ì •ë³´
            "ingredient_id": {"type": "long"},                   # ì¬ë£Œ ê³ ìœ  ID
            "name": {"type": "text", "analyzer": "nori"},        # ì¬ë£Œëª… (í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„)
            "aliases": {"type": "text", "analyzer": "nori"},     # ë™ì˜ì–´/ë³„ì¹­ (ë¬¸ìì—´ë¡œ ë³€í™˜ë¨)
            "category": {"type": "keyword"},                     # ì¬ë£Œ ì¹´í…Œê³ ë¦¬
            
            # ë²¡í„° ì„ë² ë”©
            "embedding": {
                "type": "dense_vector",
                "dims": 1536,
                "index": True,
                "similarity": "cosine"
            },
            
            # ë©”íƒ€ë°ì´í„°
            "embedding_text": {"type": "text"},
            "created_at": {"type": "date"}
        }
    },
    "settings": {
        "number_of_shards": 1,
        "number_of_replicas": 0,
        "analysis": {
            "analyzer": {
                "nori": {
                    "type": "nori",
                    "stoptags": ["E", "IC", "J", "MAG", "MM", "SP", "SSC", "SSO", "SC", "SE", "XPN", "XSA", "XSN", "XSV", "UNA", "NA", "VSV"]
                }
            }
        }
    }
}

# ============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ============================================================================

def test_connection():
    """
    OpenSearch ì„œë²„ì™€ì˜ ì—°ê²°ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
    
    Returns:
        bool: ì—°ê²° ì„±ê³µ ì‹œ True, ì‹¤íŒ¨ ì‹œ False
    """
    try:
        info = client.info()
        print(f"âœ… OpenSearch ì—°ê²° ì„±ê³µ!")
        print(f"   - ë²„ì „: {info['version']['number']}")
        print(f"   - í´ëŸ¬ìŠ¤í„°: {info['cluster_name']}")
        return True
    except Exception as e:
        print(f"âŒ OpenSearch ì—°ê²° ì‹¤íŒ¨: {e}")
        print(f"   - í˜¸ìŠ¤íŠ¸: {os.getenv('OPENSEARCH_HOST')}")
        print(f"   - ì‚¬ìš©ìëª…: {os.getenv('OPENSEARCH_USERNAME')}")
        return False

def create_index(index_name, mapping):
    """
    OpenSearchì— ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        index_name (str): ìƒì„±í•  ì¸ë±ìŠ¤ ì´ë¦„
        mapping (dict): ì¸ë±ìŠ¤ ë§¤í•‘ ì„¤ì •
    
    Returns:
        bool: ìƒì„± ì„±ê³µ ì‹œ True, ì‹¤íŒ¨ ì‹œ False
    """
    try:
        # ì¸ë±ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if not client.indices.exists(index=index_name):
            # ì¸ë±ìŠ¤ ìƒì„±
            client.indices.create(index=index_name, body=mapping)
            print(f"âœ… ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ: {index_name}")
        else:
            print(f"â„¹ï¸ ì¸ë±ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {index_name}")
        return True
    except Exception as e:
        print(f"âŒ ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨ {index_name}: {e}")
        return False

def preprocess_ingredient_data(ingredients):
    """
    ì¬ë£Œ ë°ì´í„°ë¥¼ OpenSearch ì—…ë¡œë“œìš©ìœ¼ë¡œ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    ì£¼ìš” ì‘ì—…:
    - aliases ë°°ì—´ì„ ë¬¸ìì—´ë¡œ ë³€í™˜ (OpenSearch text í•„ë“œìš©)
    - í•„ìš”í•œ í•„ë“œë§Œ ì¶”ì¶œ
    
    Args:
        ingredients (list): ì›ë³¸ ì¬ë£Œ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    
    Returns:
        list: ì „ì²˜ë¦¬ëœ ì¬ë£Œ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    processed = []
    
    for ingredient in ingredients:
        # aliases ë°°ì—´ì„ ê³µë°±ìœ¼ë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ë¡œ ë³€í™˜
        aliases = ingredient.get('aliases', [])
        if isinstance(aliases, list):
            aliases_text = ' '.join(aliases)  # ['ë°€ê°€ë£¨', 'ë°•ë ¥ë¶„'] â†’ 'ë°€ê°€ë£¨ ë°•ë ¥ë¶„'
        else:
            aliases_text = str(aliases)
        
        # OpenSearchì— ì €ì¥í•  ë°ì´í„° êµ¬ì¡° ìƒì„±
        processed_item = {
            "ingredient_id": ingredient.get('ingredient_id'),
            "name": ingredient.get('name'),
            "aliases": aliases_text,
            "category": ingredient.get('category'),
            "embedding": ingredient.get('embedding'),
            "embedding_text": ingredient.get('embedding_text'),
            "created_at": ingredient.get('created_at')
        }
        processed.append(processed_item)
    
    return processed

def preprocess_recipe_data(recipes):
    """
    ë ˆì‹œí”¼ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    í˜„ì¬ëŠ” íŠ¹ë³„í•œ ì „ì²˜ë¦¬ê°€ í•„ìš”ì—†ì§€ë§Œ, í–¥í›„ í™•ì¥ì„ ìœ„í•´ í•¨ìˆ˜ë¡œ ë¶„ë¦¬
    
    Args:
        recipes (list): ì›ë³¸ ë ˆì‹œí”¼ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    
    Returns:
        list: ì „ì²˜ë¦¬ëœ ë ˆì‹œí”¼ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    return recipes

def bulk_upload(index_name, data, batch_size=100):
    """
    ëŒ€ëŸ‰ì˜ ë°ì´í„°ë¥¼ OpenSearchì— ë°°ì¹˜ ì—…ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        index_name (str): ì—…ë¡œë“œí•  ì¸ë±ìŠ¤ëª…
        data (list): ì—…ë¡œë“œí•  ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        batch_size (int): í•œ ë²ˆì— ì²˜ë¦¬í•  ë¬¸ì„œ ìˆ˜ (ê¸°ë³¸ê°’: 100)
    
    Returns:
        bool: ëª¨ë“  ë°ì´í„° ì—…ë¡œë“œ ì„±ê³µ ì‹œ True
    """
    actions = []           # ë°°ì¹˜ ì—…ë¡œë“œìš© ì•¡ì…˜ ë¦¬ìŠ¤íŠ¸
    total = len(data)      # ì „ì²´ ë¬¸ì„œ ìˆ˜
    success_count = 0      # ì„±ê³µí•œ ì—…ë¡œë“œ ìˆ˜
    
    print(f"ğŸ“¤ {index_name} ì—…ë¡œë“œ ì‹œì‘: {total}ê°œ ë¬¸ì„œ")
    
    for i, item in enumerate(data, 1):
        # ë¬¸ì„œ ID ì„¤ì • (ê³ ìœ  ì‹ë³„ì)
        doc_id = None
        if 'recipe_id' in item:
            doc_id = item['recipe_id']
        elif 'ingredient_id' in item:
            doc_id = item['ingredient_id']
        
        # OpenSearch ì—…ë¡œë“œ ì•¡ì…˜ ìƒì„±
        action = {
            "_index": index_name,    # ì¸ë±ìŠ¤ëª…
            "_source": item          # ì‹¤ì œ ë°ì´í„°
        }
        
        # ë¬¸ì„œ IDê°€ ìˆìœ¼ë©´ ì„¤ì • (ì¤‘ë³µ ë°©ì§€)
        if doc_id:
            action["_id"] = doc_id
            
        actions.append(action)
        
        # ë°°ì¹˜ í¬ê¸°ì— ë„ë‹¬í•˜ê±°ë‚˜ ë§ˆì§€ë§‰ ë¬¸ì„œì¸ ê²½ìš° ì—…ë¡œë“œ ì‹¤í–‰
        if len(actions) >= batch_size or i == total:
            try:
                # ëŒ€ëŸ‰ ì—…ë¡œë“œ ì‹¤í–‰
                response = helpers.bulk(
                    client, 
                    actions, 
                    timeout='300s',      # 5ë¶„ íƒ€ì„ì•„ì›ƒ
                    max_retries=3        # ìµœëŒ€ 3ë²ˆ ì¬ì‹œë„
                )
                
                # ì„±ê³µí•œ ì—…ë¡œë“œ ìˆ˜ ê³„ì‚°
                success_count += len([r for r in response[1] if 'error' not in r.get('index', {})])
                
                # ì§„í–‰ë¥  ì¶œë ¥
                print(f"   ì§„í–‰ìƒí™©: {i}/{total} ({(i/total)*100:.1f}%)")
                
                actions = []  # ì•¡ì…˜ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
                time.sleep(0.1)  # API ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§§ì€ ëŒ€ê¸°
                
            except Exception as e:
                print(f"âŒ ë°°ì¹˜ ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
                
                # ë°°ì¹˜ ì—…ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê°œë³„ ì—…ë¡œë“œ ì‹œë„
                for action in actions:
                    try:
                        client.index(
                            index=action["_index"], 
                            body=action["_source"], 
                            id=action.get("_id")
                        )
                        success_count += 1
                    except:
                        pass  # ê°œë³„ ì—…ë¡œë“œë„ ì‹¤íŒ¨í•˜ë©´ ë¬´ì‹œ
                actions = []
    
    print(f"âœ… {index_name} ì—…ë¡œë“œ ì™„ë£Œ: {success_count}/{total}")
    return success_count == total

def verify_upload():
    """
    ì—…ë¡œë“œëœ ë°ì´í„°ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤.
    
    - ê° ì¸ë±ìŠ¤ì˜ ë¬¸ì„œ ìˆ˜ í™•ì¸
    - ìƒ˜í”Œ ë°ì´í„° ì¡°íšŒ
    - ì„ë² ë”© ì°¨ì›ìˆ˜ í™•ì¸
    """
    print("\nğŸ“‹ ì—…ë¡œë“œ ê²°ê³¼ ê²€ì¦:")
    
    # ë ˆì‹œí”¼ ì¸ë±ìŠ¤ ë¬¸ì„œ ìˆ˜ í™•ì¸
    try:
        recipe_count = client.count(index=RECIPE_INDEX)["count"]
        print(f"   ë ˆì‹œí”¼: {recipe_count}ê°œ")
    except Exception as e:
        print(f"   ë ˆì‹œí”¼ í™•ì¸ ì‹¤íŒ¨: {e}")
    
    # ì¬ë£Œ ì¸ë±ìŠ¤ ë¬¸ì„œ ìˆ˜ í™•ì¸
    try:
        ingredient_count = client.count(index=INGREDIENT_INDEX)["count"]
        print(f"   ì¬ë£Œ: {ingredient_count}ê°œ")
    except Exception as e:
        print(f"   ì¬ë£Œ í™•ì¸ ì‹¤íŒ¨: {e}")
    
    # ìƒ˜í”Œ ë°ì´í„° ì¡°íšŒ ë° ì„ë² ë”© ì°¨ì›ìˆ˜ í™•ì¸
    try:
        sample = client.search(
            index=INGREDIENT_INDEX, 
            body={"query": {"match_all": {}}, "size": 1}
        )
        if sample["hits"]["hits"]:
            sample_item = sample["hits"]["hits"][0]["_source"]
            print(f"   ìƒ˜í”Œ ì¬ë£Œ: {sample_item.get('name', 'N/A')}")
            print(f"   ì„ë² ë”© ì°¨ì›: {len(sample_item.get('embedding', []))}")
    except Exception as e:
        print(f"   ìƒ˜í”Œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")

# ============================================================================
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ============================================================================

def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    
    ì‹¤í–‰ ìˆœì„œ:
    1. í™˜ê²½ë³€ìˆ˜ í™•ì¸
    2. OpenSearch ì—°ê²° í…ŒìŠ¤íŠ¸
    3. ì¸ë±ìŠ¤ ìƒì„±
    4. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
    5. ëŒ€ëŸ‰ ì—…ë¡œë“œ ì‹¤í–‰
    6. ê²°ê³¼ ê²€ì¦
    """
    print("ğŸš€ OpenSearch ë°ì´í„° ì—…ë¡œë“œ ì‹œì‘\n")
    
    # 1. í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ í™•ì¸
    required_vars = ['OPENSEARCH_HOST']
    for var in required_vars:
        if not os.getenv(var):
            print(f"âŒ {var} í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return
    
    # Username/Password ë˜ëŠ” AWS ì¸ì¦ ì¤‘ í•˜ë‚˜ëŠ” ìˆì–´ì•¼ í•¨
    if not (os.getenv('OPENSEARCH_USERNAME') and os.getenv('OPENSEARCH_PASSWORD')):
        if not os.getenv('AWS_REGION'):
            print("âŒ ì¸ì¦ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. Username/Password ë˜ëŠ” AWS ì¸ì¦ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            return
    
    # 2. OpenSearch ì—°ê²° í…ŒìŠ¤íŠ¸
    if not test_connection():
        return
    
    # 3. ì¸ë±ìŠ¤ ìƒì„±
    print("\nğŸ“‚ ì¸ë±ìŠ¤ ìƒì„±:")
    if not create_index(RECIPE_INDEX, recipe_mapping):
        return
    if not create_index(INGREDIENT_INDEX, ingredient_mapping):
        return
    
    # ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ ëŒ€ê¸°
    time.sleep(2)
    
    # 4. ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì •
    # í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë”°ë¼ ê²½ë¡œ ì¡°ì •
    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    
    print("\nğŸ“¤ ë°ì´í„° ì—…ë¡œë“œ:")
    
    # 5-1. ë ˆì‹œí”¼ ë°ì´í„° ì—…ë¡œë“œ
    recipe_file = os.path.join(base_dir, "data", "recipe_embeddings.json")
    if os.path.exists(recipe_file):
        print(f"ğŸ“ ë ˆì‹œí”¼ íŒŒì¼ ë¡œë“œ: {recipe_file}")
        with open(recipe_file, 'r', encoding='utf-8') as f:
            recipes = json.load(f)
        
        # ì „ì²˜ë¦¬ ë° ì—…ë¡œë“œ
        processed_recipes = preprocess_recipe_data(recipes)
        bulk_upload(RECIPE_INDEX, processed_recipes)
    else:
        print(f"âŒ ë ˆì‹œí”¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {recipe_file}")
        print(f"   í˜„ì¬ ê²½ë¡œì—ì„œ ì°¾ì•„ë³´ì„¸ìš”: ./recipe_embeddings.json")
    
    # 5-2. ì¬ë£Œ ë°ì´í„° ì—…ë¡œë“œ
    ingredient_file = os.path.join(base_dir, "data", "ingredient_embeddings.json")
    if os.path.exists(ingredient_file):
        print(f"ğŸ“ ì¬ë£Œ íŒŒì¼ ë¡œë“œ: {ingredient_file}")
        with open(ingredient_file, 'r', encoding='utf-8') as f:
            ingredients = json.load(f)
        
        # ì „ì²˜ë¦¬ ë° ì—…ë¡œë“œ (aliases ë°°ì—´ â†’ ë¬¸ìì—´ ë³€í™˜)
        processed_ingredients = preprocess_ingredient_data(ingredients)
        bulk_upload(INGREDIENT_INDEX, processed_ingredients)
    else:
        print(f"âŒ ì¬ë£Œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {ingredient_file}")
        print(f"   í˜„ì¬ ê²½ë¡œì—ì„œ ì°¾ì•„ë³´ì„¸ìš”: ./ingredient_embeddings.json")
    
    # 6. ì¸ë±ì‹± ì™„ë£Œ ëŒ€ê¸°
    print("\nâ³ ì¸ë±ì‹± ì™„ë£Œ ëŒ€ê¸° ì¤‘...")
    time.sleep(5)
    
    # 7. ì—…ë¡œë“œ ê²°ê³¼ ê²€ì¦
    verify_upload()
    
    print("\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("\nğŸ“– ë‹¤ìŒ ë‹¨ê³„:")
    print("   1. AI ì„œë²„ì—ì„œ ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    print("   2. ë„¤íŠ¸ì›Œí¬ ì„¤ì •ì„ VPCë¡œ ë³µì› (ë³´ì•ˆ ê°•í™”)")
    print("   3. ë ˆì‹œí”¼ ì¶”ì²œ API ê°œë°œ")

# ============================================================================
# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
# ============================================================================

if __name__ == "__main__":
    main()